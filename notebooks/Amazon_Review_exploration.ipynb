{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read in Review Files and create a pandas dataframe (code borrowed from Julian McAuley website) ##\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "food_review = getDF('../data/reviews_Grocery_and_Gourmet_Food_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Remove special characters for the review text\n",
    "food_review['reviewText'] = food_review['reviewText'].str.replace(\"'\", \"\")\n",
    "food_review['reviewText'] = food_review['reviewText'].str.replace('[^a-zA-Z\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Test file:  Exclude five star reviews from 5 Core\n",
    "food_review_nofive = food_review[food_review['overall'] < 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Tokenize review text for each review\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "\n",
    "tokens_I = [word_tokenize(review) for review in food_review_nofive['reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Separate strings with multiple uppercase characters (e.g., gCholesterol, VeronaStarbucks).  This should (hopefully)\n",
    "## take care of situations where the reviews included returns that were not treated as spaces in the raw text file\n",
    "import re\n",
    "def split_uppercase(value):\n",
    "    return re.sub(r'([A-Z])', r' \\1', value)\n",
    "\n",
    "tokens_II = np.empty((len(tokens_I),0)).tolist()\n",
    "for review in tokens_I:\n",
    "    n = tokens_I.index(review)\n",
    "    tokens_II[n] = [split_uppercase(word) for word in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Make all text lower case\n",
    "tokens = np.empty((len(tokens_II),0)).tolist()\n",
    "for review in tokens_II:\n",
    "    n = tokens_II.index(review)\n",
    "    tokens[n] = [word.lower() for word in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Remove stopwords and stem\n",
    "stopwords = stopwords.words('english')\n",
    "stemmed_token = np.empty((len(tokens),0)).tolist()\n",
    "for review in tokens:\n",
    "    n = tokens.index(review)\n",
    "    stemmed_token[n] = [st.stem(word) for word in review if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Manipulate stemmed text to be string instead of list (needed for count vectorizer)\n",
    "final_review_text = []\n",
    "for review in stemmed_token:\n",
    "    for word in review:\n",
    "        n = review.index(word)\n",
    "        if n == 0:\n",
    "            string = review[n]\n",
    "        else:\n",
    "            string = string + \" \" + review[n]\n",
    "    final_review_text.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Count Vectorizer Matrix\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=False, ngram_range=(1, 1)) ##Removed stopwords before stemming so don't apply here\n",
    "food_review_text = vectorizer.fit_transform(final_review_text)\n",
    "\n",
    "##Remove if word is in less than 10 reviews\n",
    "counts = scipy.sparse.coo_matrix.sum(food_review_text, axis=0)\n",
    "food_review_text = np.transpose(vstack([food_review_text,counts]))\n",
    "food_review_text = pd.DataFrame(food_review_text.todense(), index = vectorizer.get_feature_names())\n",
    "last_col = food_review_text.shape[1] - 1\n",
    "food_review_text = food_review_text[food_review_text[last_col] > 9]\n",
    "del food_review_text[last_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63808x7051 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2061758 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TFIDF Weighting\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "weighted_food_review_text = transformer.fit_transform(food_review_text)\n",
    "tfidf_matrix = weighted_food_review_text.transpose()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Non-negative matrix factorization\n",
    "n_topics = 20\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(init=\"nndsvd\", n_components=n_topics, random_state=1)\n",
    "W_matrix = model.fit_transform(tfidf_matrix)\n",
    "H_matrix = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: eat, snack, the, chocol, pack, they, bar, lik, box, good\n",
      "Topic 1: nutry, insulin, canyon, worthless, cm, sesam, hemp, highest, rancid, regardless\n",
      "Topic 2: mahogony, lodge, kopi, raya, jazzed, emeril, xtra, wolfgang, mountain, reserve\n",
      "Topic 3: folic, sodium, color, calcium, sugars, mononitrate, niacinamide, dietary, total, sulfate\n",
      "Topic 4: compass, gratitud, uplift, soul, wisdom, prevail, grac, enlight, attitud, mercy\n",
      "Topic 5: unfiltered, unrefined, unknown, fahrenheit, virgin, trade, press, certified, kosher, unrefin\n",
      "Topic 6: preterm, newborn, scientists, cocain, vuln, infant, mo, inf, cholin, polysaccharid\n",
      "Topic 7: sprats, baltic, filet, fish, her, fillets, kipper, fillet, seas, herring\n",
      "Topic 8: umam, glutam, inosin, arroz, silicon, autolys, overus, disod, dioxid, mi\n",
      "Topic 9: regulations, federal, enzymolys, unexplain, code, oleoresin, der, constitu, thereof, poultry\n",
      "Topic 10: sauc, cook, dish, ad, past, chick, minut, prep, heat, tomato\n",
      "Topic 11: ikkoku, maison, exquisit, celest, rendit, deplet, sencha, enorm, altitud, en\n",
      "Topic 12: citicolin, nawgan, cognizin, mikes, hydrochlorid, pyridoxin, alph, acet, carot, cyanocobalamin\n",
      "Topic 13: brite, cleaner, scotch, pad, cle, scrubbing, buff, scrubber, cooktop, stov\n",
      "Topic 14: defec, phytosterols, musc, chia, eicosapentaeno, chi, gr, unw, docosahexaeno, omeg\n",
      "Topic 15: erythritol, nectresse, sucros, monk, nectress, menthol, sug, sweet, swerve, stev\n",
      "Topic 16: diatomac, wedderspoon, scab, pol, unfilt, ass, honey, rejuv, purchasing, viscos\n",
      "Topic 17: drink, tea, energy, wat, tast, caffein, juic, flav, bottl, lik\n",
      "Topic 18: stream, liter, markup, brita, costs, restaurant, refil, soda, lit, sixteen\n",
      "Topic 19: coff, cup, brew, keurig, coffee, roast, ground, filt, machin, blend\n"
     ]
    }
   ],
   "source": [
    "##Prints tops and keywords\n",
    "\n",
    "feature_names = food_review_text.index\n",
    "for topic_index in range( H_matrix.shape[0] ):\n",
    "    top_indices = np.argsort( H_matrix[topic_index,:] )[::-1][0:10]  ##show top 10 words associated with each topic\n",
    "    term_ranking = [feature_names[i] for i in top_indices]\n",
    "    print (\"Topic %d: %s\" % ( topic_index, \", \".join( term_ranking ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
