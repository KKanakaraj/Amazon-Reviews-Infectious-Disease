{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling the amazon reviews with Afinn sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...)\n",
    "\n",
    "- Sentiment score from all of the words in Amazon reviews.\n",
    "- Sentiment score from only the most frequent words in Amazon reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment score from all of the words in Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import gensim\n",
    "import collections\n",
    "from afinn import Afinn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tajimakeijiro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tajimakeijiro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download stopwords and wordnet for lemmatization (only need to be executed once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a json file made in the notebook \"Milestone2.ipynb\".\n",
    "REVIEWS_PATH = \"cleaned_reviews.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A1ZQZ8RJS1XVTX</td>\n",
       "      <td>0657745316</td>\n",
       "      <td>No sugar, no GMO garbage, no fillers that come...</td>\n",
       "      <td>5</td>\n",
       "      <td>Best vanilla I've ever had</td>\n",
       "      <td>2013-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A31W38VGZAUUM4</td>\n",
       "      <td>0700026444</td>\n",
       "      <td>This is my absolute, undisputed favorite tea r...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific Tea!</td>\n",
       "      <td>2012-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A3I0AV0UJX5OH0</td>\n",
       "      <td>1403796890</td>\n",
       "      <td>I ordered spongbob slippers and I got John Cen...</td>\n",
       "      <td>1</td>\n",
       "      <td>grrrrrrr</td>\n",
       "      <td>2013-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A3QAAOLIXKV383</td>\n",
       "      <td>1403796890</td>\n",
       "      <td>The cart is fine and works for the purpose for...</td>\n",
       "      <td>3</td>\n",
       "      <td>Storage on Wheels Cart</td>\n",
       "      <td>2011-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AB1A5EGHHVA9M</td>\n",
       "      <td>141278509X</td>\n",
       "      <td>This product by Archer Farms is the best drink...</td>\n",
       "      <td>5</td>\n",
       "      <td>The best drink mix</td>\n",
       "      <td>2012-03-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A1ZQZ8RJS1XVTX  0657745316   \n",
       "1  A31W38VGZAUUM4  0700026444   \n",
       "2  A3I0AV0UJX5OH0  1403796890   \n",
       "3  A3QAAOLIXKV383  1403796890   \n",
       "4   AB1A5EGHHVA9M  141278509X   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  No sugar, no GMO garbage, no fillers that come...        5   \n",
       "1  This is my absolute, undisputed favorite tea r...        5   \n",
       "2  I ordered spongbob slippers and I got John Cen...        1   \n",
       "3  The cart is fine and works for the purpose for...        3   \n",
       "4  This product by Archer Farms is the best drink...        5   \n",
       "\n",
       "                      summary unixReviewTime  \n",
       "0  Best vanilla I've ever had     2013-10-11  \n",
       "1               Terrific Tea!     2012-12-06  \n",
       "2                    grrrrrrr     2013-12-02  \n",
       "3      Storage on Wheels Cart     2011-06-12  \n",
       "4          The best drink mix     2012-03-24  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_json(REVIEWS_PATH, lines=True)\n",
    "\n",
    "#TBD: Which columns to keep/remove\n",
    "reviews = reviews.drop(columns=['reviewerName', 'helpful', 'reviewTime'])\n",
    "\n",
    "#Convert the utc timestamp to readable dates\n",
    "reviews['unixReviewTime'] = pd.to_datetime(reviews['unixReviewTime'],unit='s')\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to process the reviews using the nltk library :\n",
    "* We tokenize the sentence,\n",
    "* remove any potential stop words,\n",
    "* remove tokens containing only punctuations (such as '!!!', '...', etc.. which where quite common),\n",
    "* remove words below a given length,\n",
    "* stem the words to have them all represented in a standardized way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ordered', 'spongbob', 'slippers', 'got', 'john']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Here we don't need stemming, because Afinn has same score for the before stemmed ones.\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "def process_text(sentence):\n",
    "    token_words = nltk.word_tokenize(sentence)\n",
    "    no_stopwords = [word.lower() for word in token_words if word not in stop_words and not \\\n",
    "                    all(c in string.punctuation for c in word) and not len(word) < 2]\n",
    "    # return [stemmer.stem(word) for word in no_stopwords]\n",
    "    return [(word) for word in no_stopwords]\n",
    "\n",
    "print(process_text('I ordered spongbob slippers and I got John'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a new column to our dataframe containing the processed reviewText (notice that we only keep reviews with a low score, under the fair assumption that reviews exposing health issues would have a low rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewStemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A3I0AV0UJX5OH0</td>\n",
       "      <td>1403796890</td>\n",
       "      <td>I ordered spongbob slippers and I got John Cen...</td>\n",
       "      <td>1</td>\n",
       "      <td>grrrrrrr</td>\n",
       "      <td>2013-12-02</td>\n",
       "      <td>[ordered, spongbob, slippers, got, john, cena,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>A3DTB6RVENLQ9Q</td>\n",
       "      <td>1453060375</td>\n",
       "      <td>Don't buy this item - rip off at this price.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oops.  Made a mistake and ordered this.  I mis...</td>\n",
       "      <td>2013-03-03</td>\n",
       "      <td>[do, n't, buy, item, rip, price, my, bad, mist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>A3KJ9TZ2HLL7SA</td>\n",
       "      <td>5901002482</td>\n",
       "      <td>I wrote an earlier scathing review of this pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Packaging problem</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>[wrote, earlier, scathing, review, product, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>ACEL2LY99MAB0</td>\n",
       "      <td>6162362183</td>\n",
       "      <td>I read the reviews before I bought it. It got ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Very disappointed.</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>[read, reviews, bought, it, got, excited, revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>A2F3CK8F9VIFPL</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I bought it because i like green tea but the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yuck</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>[bought, like, green, tea, taste, bad, came, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID        asin  \\\n",
       "2   A3I0AV0UJX5OH0  1403796890   \n",
       "5   A3DTB6RVENLQ9Q  1453060375   \n",
       "46  A3KJ9TZ2HLL7SA  5901002482   \n",
       "48   ACEL2LY99MAB0  6162362183   \n",
       "61  A2F3CK8F9VIFPL  616719923X   \n",
       "\n",
       "                                           reviewText  overall  \\\n",
       "2   I ordered spongbob slippers and I got John Cen...        1   \n",
       "5   Don't buy this item - rip off at this price.  ...        1   \n",
       "46  I wrote an earlier scathing review of this pro...        1   \n",
       "48  I read the reviews before I bought it. It got ...        2   \n",
       "61  I bought it because i like green tea but the t...        1   \n",
       "\n",
       "                                              summary unixReviewTime  \\\n",
       "2                                            grrrrrrr     2013-12-02   \n",
       "5   Oops.  Made a mistake and ordered this.  I mis...     2013-03-03   \n",
       "46                                  Packaging problem     2012-11-28   \n",
       "48                                 Very disappointed.     2014-04-21   \n",
       "61                                               Yuck     2013-07-29   \n",
       "\n",
       "                                        reviewStemmed  \n",
       "2   [ordered, spongbob, slippers, got, john, cena,...  \n",
       "5   [do, n't, buy, item, rip, price, my, bad, mist...  \n",
       "46  [wrote, earlier, scathing, review, product, wh...  \n",
       "48  [read, reviews, bought, it, got, excited, revi...  \n",
       "61  [bought, like, green, tea, taste, bad, came, m...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed = reviews.copy()\n",
    "stemmed = stemmed[stemmed['overall'] < 3]\n",
    "stemmed['reviewStemmed'] = stemmed['reviewText'].apply(lambda x : process_text(x))\n",
    "\n",
    "stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply store the dataframe in a pickle for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmed.to_pickle(\"reviews_tokened_tenth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = Afinn()\n",
    "\n",
    "# This cell takes long\n",
    "stemmed['afinnWords'] = stemmed['reviewText'].apply(lambda x : afinn.find_all(x))\n",
    "stemmed['afinnScores'] = stemmed['reviewText'].apply(lambda x : afinn.scores_with_pattern(x))\n",
    "stemmed['afinnTotalScore'] = stemmed['reviewText'].apply(lambda x : afinn.score_with_pattern(x))\n",
    "stemmed['afinnWordsLen'] = stemmed['afinnWords'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewStemmed</th>\n",
       "      <th>afinnWords</th>\n",
       "      <th>afinnScores</th>\n",
       "      <th>afinnTotalScore</th>\n",
       "      <th>afinnWordsLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A3I0AV0UJX5OH0</td>\n",
       "      <td>1403796890</td>\n",
       "      <td>I ordered spongbob slippers and I got John Cen...</td>\n",
       "      <td>1</td>\n",
       "      <td>grrrrrrr</td>\n",
       "      <td>2013-12-02</td>\n",
       "      <td>[ordered, spongbob, slippers, got, john, cena,...</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>A3DTB6RVENLQ9Q</td>\n",
       "      <td>1453060375</td>\n",
       "      <td>Don't buy this item - rip off at this price.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Oops.  Made a mistake and ordered this.  I mis...</td>\n",
       "      <td>2013-03-03</td>\n",
       "      <td>[do, n't, buy, item, rip, price, my, bad, mist...</td>\n",
       "      <td>[bad, mistake, pay, pay]</td>\n",
       "      <td>[-3, -2, -1, -1]</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>A3KJ9TZ2HLL7SA</td>\n",
       "      <td>5901002482</td>\n",
       "      <td>I wrote an earlier scathing review of this pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Packaging problem</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>[wrote, earlier, scathing, review, product, wh...</td>\n",
       "      <td>[harsh, apologize, disappointed, protect, hope...</td>\n",
       "      <td>[-2, -1, -2, 1, 2, -2]</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>ACEL2LY99MAB0</td>\n",
       "      <td>6162362183</td>\n",
       "      <td>I read the reviews before I bought it. It got ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Very disappointed.</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>[read, reviews, bought, it, got, excited, revi...</td>\n",
       "      <td>[excited, good, destroyed, mad, disappointed, ...</td>\n",
       "      <td>[3, 3, -3, -3, -2, 3]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>A2F3CK8F9VIFPL</td>\n",
       "      <td>616719923X</td>\n",
       "      <td>I bought it because i like green tea but the t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yuck</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>[bought, like, green, tea, taste, bad, came, m...</td>\n",
       "      <td>[like, bad]</td>\n",
       "      <td>[2, -3]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID        asin  \\\n",
       "2   A3I0AV0UJX5OH0  1403796890   \n",
       "5   A3DTB6RVENLQ9Q  1453060375   \n",
       "46  A3KJ9TZ2HLL7SA  5901002482   \n",
       "48   ACEL2LY99MAB0  6162362183   \n",
       "61  A2F3CK8F9VIFPL  616719923X   \n",
       "\n",
       "                                           reviewText  overall  \\\n",
       "2   I ordered spongbob slippers and I got John Cen...        1   \n",
       "5   Don't buy this item - rip off at this price.  ...        1   \n",
       "46  I wrote an earlier scathing review of this pro...        1   \n",
       "48  I read the reviews before I bought it. It got ...        2   \n",
       "61  I bought it because i like green tea but the t...        1   \n",
       "\n",
       "                                              summary unixReviewTime  \\\n",
       "2                                            grrrrrrr     2013-12-02   \n",
       "5   Oops.  Made a mistake and ordered this.  I mis...     2013-03-03   \n",
       "46                                  Packaging problem     2012-11-28   \n",
       "48                                 Very disappointed.     2014-04-21   \n",
       "61                                               Yuck     2013-07-29   \n",
       "\n",
       "                                        reviewStemmed  \\\n",
       "2   [ordered, spongbob, slippers, got, john, cena,...   \n",
       "5   [do, n't, buy, item, rip, price, my, bad, mist...   \n",
       "46  [wrote, earlier, scathing, review, product, wh...   \n",
       "48  [read, reviews, bought, it, got, excited, revi...   \n",
       "61  [bought, like, green, tea, taste, bad, came, m...   \n",
       "\n",
       "                                           afinnWords             afinnScores  \\\n",
       "2                                             [happy]                     [3]   \n",
       "5                            [bad, mistake, pay, pay]        [-3, -2, -1, -1]   \n",
       "46  [harsh, apologize, disappointed, protect, hope...  [-2, -1, -2, 1, 2, -2]   \n",
       "48  [excited, good, destroyed, mad, disappointed, ...   [3, 3, -3, -3, -2, 3]   \n",
       "61                                        [like, bad]                 [2, -3]   \n",
       "\n",
       "    afinnTotalScore  afinnWordsLen  \n",
       "2               3.0              1  \n",
       "5              -7.0              4  \n",
       "46             -4.0              6  \n",
       "48              1.0              6  \n",
       "61             -1.0              2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">overall</th>\n",
       "      <th colspan=\"8\" halign=\"left\">afinnTotalScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afinnWordsLen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7287.0</td>\n",
       "      <td>1.346370</td>\n",
       "      <td>0.475846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7287.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19320.0</td>\n",
       "      <td>1.381832</td>\n",
       "      <td>0.485848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19320.0</td>\n",
       "      <td>0.389337</td>\n",
       "      <td>2.176076</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26116.0</td>\n",
       "      <td>1.384515</td>\n",
       "      <td>0.486490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26116.0</td>\n",
       "      <td>0.798399</td>\n",
       "      <td>3.138037</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25653.0</td>\n",
       "      <td>1.381008</td>\n",
       "      <td>0.485644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25653.0</td>\n",
       "      <td>1.143219</td>\n",
       "      <td>3.932941</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>1.375498</td>\n",
       "      <td>0.484263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>1.550296</td>\n",
       "      <td>4.658668</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>89.095454</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>129.0</td>\n",
       "      <td>160.5</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               overall                                               \\\n",
       "                 count      mean       std  min  25%  50%  75%  max   \n",
       "afinnWordsLen                                                         \n",
       "0               7287.0  1.346370  0.475846  1.0  1.0  1.0  2.0  2.0   \n",
       "1              19320.0  1.381832  0.485848  1.0  1.0  1.0  2.0  2.0   \n",
       "2              26116.0  1.384515  0.486490  1.0  1.0  1.0  2.0  2.0   \n",
       "3              25653.0  1.381008  0.485644  1.0  1.0  1.0  2.0  2.0   \n",
       "4              20578.0  1.375498  0.484263  1.0  1.0  1.0  2.0  2.0   \n",
       "...                ...       ...       ...  ...  ...  ...  ...  ...   \n",
       "140                1.0  2.000000       NaN  2.0  2.0  2.0  2.0  2.0   \n",
       "142                2.0  1.000000  0.000000  1.0  1.0  1.0  1.0  1.0   \n",
       "180                1.0  1.000000       NaN  1.0  1.0  1.0  1.0  1.0   \n",
       "202                1.0  1.000000       NaN  1.0  1.0  1.0  1.0  1.0   \n",
       "247                1.0  2.000000       NaN  2.0  2.0  2.0  2.0  2.0   \n",
       "\n",
       "              afinnTotalScore                                              \\\n",
       "                        count        mean        std    min    25%    50%   \n",
       "afinnWordsLen                                                               \n",
       "0                      7287.0    0.000000   0.000000    0.0    0.0    0.0   \n",
       "1                     19320.0    0.389337   2.176076   -4.0   -2.0    1.0   \n",
       "2                     26116.0    0.798399   3.138037   -8.0   -1.0    1.0   \n",
       "3                     25653.0    1.143219   3.932941  -10.0   -2.0    1.0   \n",
       "4                     20578.0    1.550296   4.658668  -13.0   -2.0    2.0   \n",
       "...                       ...         ...        ...    ...    ...    ...   \n",
       "140                       1.0   -1.000000        NaN   -1.0   -1.0   -1.0   \n",
       "142                       2.0  129.000000  89.095454   66.0   97.5  129.0   \n",
       "180                       1.0   -7.000000        NaN   -7.0   -7.0   -7.0   \n",
       "202                       1.0   52.000000        NaN   52.0   52.0   52.0   \n",
       "247                       1.0  400.000000        NaN  400.0  400.0  400.0   \n",
       "\n",
       "                             \n",
       "                 75%    max  \n",
       "afinnWordsLen                \n",
       "0                0.0    0.0  \n",
       "1                2.0    5.0  \n",
       "2                4.0    9.0  \n",
       "3                4.0   12.0  \n",
       "4                5.0   14.0  \n",
       "...              ...    ...  \n",
       "140             -1.0   -1.0  \n",
       "142            160.5  192.0  \n",
       "180             -7.0   -7.0  \n",
       "202             52.0   52.0  \n",
       "247            400.0  400.0  \n",
       "\n",
       "[93 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed.groupby(by=['afinnWordsLen']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment score from only the most frequent words in Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_list):\n",
    "    return [e for inner_list in nested_list for e in inner_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_stemmed = stemmed['reviewStemmed'].values.tolist()\n",
    "l_stemmed = flatten(l_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentWords = collections.Counter(l_stemmed).most_common()[0:50000]\n",
    "frequentWords = [word for word, count in frequentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_frequent = stemmed.copy()\n",
    "stemmed_frequent['afinnWords'] = stemmed['afinnWords'].apply(lambda x : [i for i in x if i in frequentWords])\n",
    "stemmed_frequent['afinnScores'] = stemmed_frequent['reviewText'].apply(lambda x : afinn.scores_with_pattern(x))\n",
    "stemmed_frequent['afinnTotalScore'] = stemmed_frequent['reviewText'].apply(lambda x : afinn.score_with_pattern(x))\n",
    "stemmed_frequent['afinnWordsLen'] = stemmed_frequent['afinnWords'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed.groupby(by=['afinnWordsLen']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
